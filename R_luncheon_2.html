<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="js/google-analytics.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">SCCWRP R training</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Intro_to_R.html">Introduction to R</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data wrangling
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Data_Wrangling_1.html">Part 1</a>
    </li>
    <li>
      <a href="Data_Wrangling_2.html">Part 2</a>
    </li>
  </ul>
</li>
<li>
  <a href="Viz_and_Graphics.html">Viz and graphics</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    R luncheons
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R_luncheon_1.html">R luncheon 1</a>
    </li>
    <li>
      <a href="R_luncheon_2.html">R luncheon 2</a>
    </li>
    <li>
      <a href="R_luncheon_3.html">R luncheon 3</a>
    </li>
    <li>
      <a href="R_luncheon_4.html">R luncheon 4</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="r-luncheon-2" class="section level1">
<h1>R luncheon 2</h1>
<div id="lesson-outline" class="section level2">
<h2>Lesson Outline</h2>
<ul>
<li><a href="#problem-scope">Problem scope</a></li>
<li><a href="#housekeeping">Housekeeping</a></li>
<li><a href="#data-import">Data import</a></li>
<li><a href="#data-wrangle">Data wrangle</a></li>
<li><a href="#data-analysis">Data analysis</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<p>Welcome to the second R luncheon! The format for this session will be similar to the first, with the general goal of better understanding how we can use R to approach real-world examples in bite size chunks. The discussion will contain four parts:</p>
<ol style="list-style-type: decimal">
<li><p>Presentation of the problem: what we are starting with and where we want to go</p></li>
<li><p>Steps to address the problem in general terms</p></li>
<li><p>Specific steps to address the problem using R</p></li>
<li><p>Execution of the workflow to achieve the final product</p></li>
</ol>
<p>Please note that this is not an introduction to R. You can visit any of the other topics on our <a href="index.html">main page</a> for a refresher on some of the basics. In the mean time, feel free to ask plenty of questions as we go through today’s lesson!</p>
</div>
</div>
<div id="problem-scope" class="section level1">
<h1>Problem scope</h1>
<p>Today’s session will focus on a sediment chemistry dataset for several monitoring sites along the coast. The raw data are provided in two separate Excel spreadsheets, one containing the <a href="https://sccwrp.github.io/SCCWRP_R_training/data/Sed_chem_tox%20-%20expanded.xlsx">sediment data</a> and the other containing station <a href="https://sccwrp.github.io/SCCWRP_R_training/data/AllBightStationLocations.csv">location data</a>. Each site in the dataset has estimates of the concentration of different contaminants (e.g., mercury, lead, etc.) that were found in the sediment samples. Toxicity tests were also conducted for each sample that evaluated the mortality/survivorship of organisms that were exposed to the sediment.</p>
<p><img src="figure/sedsnap.JPG" /> <img src="figure/sedsnap2.JPG" /></p>
<p>Our goal for this dataset is to explore relationships among the stations to identify:</p>
<ol style="list-style-type: decimal">
<li><p>Spatial patterns among the measurements, and</p></li>
<li><p>Characterize any association of these measurements with mortality/survivorship.</p></li>
</ol>
<p>This type of information can help identify which pollutants are of most concern and where efforts should be focused to minimize exposure risk. Alternatively, monitoring is expensive and it can help identify which measurements may not need to be sampled as frequently.</p>
<p>This dataset is a perfect example of a real-world analysis challenge. The data are provided with minimal background and the goal of the analysis is very general. We don’t know where the stations are located, nor do we have any prior knowledge about expected patterns. As a result, the analysis will be exploratory and a relatively flexible approach will be used to answer the research question. Our steps will include:</p>
<ol style="list-style-type: decimal">
<li><p>Import the station chemistry data and station location data</p></li>
<li><p>Wrangle the data to a consistent format. This will include formatting the chemistry data to deal with any Excel artifacts and joining the final dataset with the location data for plotting. We’ll also have to think about dealing with outliers or other “incorrect” data. This is a guarantee with such a large dataset.</p></li>
<li><p>Evaluate any spatial relationships among the variables. Do any measurements relate to depth? What about latitude or longitude?</p></li>
<li><p>Evaluate assocations of the chemistry data with results from the toxicity tests. Are any variables standing out? What are any other challenges we need to consider?</p></li>
</ol>
<div class="figure">
<img src="figure/luncheon2workflow.png" />

</div>
</div>
<div id="housekeeping" class="section level1">
<h1>Housekeeping</h1>
<p>Let’s start by opening RStudio, creating a new project, and downloading the data to the project.</p>
<div id="open-rstudio" class="section level2">
<h2>Open RStudio</h2>
<p>Find the RStudio shortcut and fire it up. You should see something like this:</p>
<div class="figure">
<img src="figure/rstudio.png" />

</div>
</div>
<div id="create-a-new-project-in-rstudio" class="section level2">
<h2>Create a new project in RStudio</h2>
<p>To create a new project, click on the File menu at the top and select ‘New project…’</p>
<div class="figure">
<img src="figure/rstudio_proj.jpg" />

</div>
</div>
<div id="download-the-data-to-your-project" class="section level2">
<h2>Download the data to your project</h2>
<p>You can download the two data files from this <a href="https://sccwrp.github.io/SCCWRP_R_training/data/Sed_chem_tox%20-%20expanded.xlsx">link</a> for the chemistry data and this <a href="https://sccwrp.github.io/SCCWRP_R_training/data/AllBightStationLocations.csv">link</a> for the station locations. Once downloaded, you’ll have to copy and paste the Excel file to your project. Run <code>getwd()</code> in the R console if you’re not sure where this is.</p>
<p>You can also download the data file directly in R. This will download the data and save the file to your new RStudio project in a single step.</p>
<pre class="r"><code># download the first file
download.file(
  url = &#39;https://sccwrp.github.io/SCCWRP_R_training/data/Sed_chem_tox - expanded.xlsx&#39;,
  destfile = &#39;Sed_chem_tox - expanded.xlsx&#39;
  )

# download the second file
download.file(
  url = &#39;https://sccwrp.github.io/SCCWRP_R_training/data/AllBightStationLocations.csv&#39;,
  destfile = &#39;AllBightStationLocations.csv&#39;
  )</code></pre>
</div>
</div>
<div id="data-import" class="section level1">
<h1>Data import</h1>
<p>Now that we’ve got our project setup with the data, let’s open a new script and load some R packages that we’ll be using.</p>
<p>Open a new script from the File menu…</p>
<div class="figure">
<img src="figure/rstudio_script.jpg" />

</div>
<p>Once the script is open, save it using the drop down file menu on the top left. Give it an informative name (e.g.,<code>Rluncheon2.R</code>) and save it in your project’s home directory. This should be the default location selected by RStudio when you save the file.</p>
<p>We’ll be using functions from the <a href="https://www.tidyverse.org/">tidyverse</a> collection of packages to import, wrangle, and plot the data. Checkout our training material <a href="https://sccwrp.github.io/SCCWRP_R_training/Data_Wrangling_1.html#the-tidyverse">here</a> if you need a brush up. Run this line in the R console if you don’t have the tidyverse installed.</p>
<pre class="r"><code>install.packages(&#39;tidyverse&#39;)</code></pre>
<p>In the script you just opened, add the following lines to load the tidyverse package and the readxl package (for data import).</p>
<pre class="r"><code>library(tidyverse)
library(readxl)</code></pre>
<p>Then add this line to import the chemistry dataset using the <code>read_excel()</code> function. The imported dataset will be assigned to the <code>datchem</code> variable in the workspace for your current R session. We’ll import the station location data using the base R function <code>read.csv</code>. As a side note, you want to always use the argument <code>stringsAsFactors = F</code> when importing data with <code>read.csv</code>. This will ensure that any column that looks like character data will actually be imported as character data. Otherwise, the data are imported as factors, which is not wrong but there may be undesired side effects later on (more info <a href="http://www.win-vector.com/blog/2018/03/r-tip-use-stringsasfactors-false/">here</a>).</p>
<pre class="r"><code>datchem &lt;- read_excel(&#39;Sed_chem_tox - expanded.xlsx&#39;)
datlocs &lt;- read.csv(&#39;AllBightStationLocations.csv&#39;, stringsAsFactors = F)</code></pre>
<p>Let’s get a feel for the dataset before we proceed.</p>
<pre class="r"><code>head(datchem)</code></pre>
<pre><code>## # A tibble: 6 x 15
##   `Station ID` `Depth\r\n(m)` `Amphipod surviv~ X__1  `%M.Emb.Surv.` Al   
##          &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;
## 1           NA           NA   raw data          %Amp~ &lt;NA&gt;           &lt;NA&gt; 
## 2         6001            0.9 18.2              91    90             1040 
## 3         6004            0.8 18.4000000000000~ 92    100            6690 
## 4         6009            0.6 18                90    0              12700
## 5         6010            0.6 17.3999999999999~ 87    95             2615 
## 6         6012            0.8 19                95    95             4444 
## # ... with 9 more variables: As &lt;chr&gt;, Cr &lt;dbl&gt;, Cu &lt;dbl&gt;, Fe &lt;dbl&gt;,
## #   Pb &lt;dbl&gt;, Hg &lt;dbl&gt;, Ni &lt;dbl&gt;, Zn &lt;dbl&gt;, X__2 &lt;chr&gt;</code></pre>
<pre class="r"><code>str(datchem)</code></pre>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    156 obs. of  15 variables:
##  $ Station ID               : num  NA 6001 6004 6009 6010 ...
##  $ Depth
## (m)             : num  NA 0.9 0.8 0.6 0.6 0.8 1.8 1.5 3.7 3.5 ...
##  $ Amphipod survival (n =20): chr  &quot;raw data&quot; &quot;18.2&quot; &quot;18.400000000000002&quot; &quot;18&quot; ...
##  $ X__1                     : chr  &quot;%Amph.&quot; &quot;91&quot; &quot;92&quot; &quot;90&quot; ...
##  $ %M.Emb.Surv.             : chr  NA &quot;90&quot; &quot;100&quot; &quot;0&quot; ...
##  $ Al                       : chr  NA &quot;1040&quot; &quot;6690&quot; &quot;12700&quot; ...
##  $ As                       : chr  NA &quot;1&quot; &quot;1.4&quot; &quot;3.1&quot; ...
##  $ Cr                       : num  NA 1.4 7.7 13.3 2.6 4.1 47.3 18.5 36.4 36.1 ...
##  $ Cu                       : num  NA 0.5 6 13 1.9 ...
##  $ Fe                       : num  NA 1726 8100 13900 3192 ...
##  $ Pb                       : num  NA 0.7 4.1 10 1.4 2.5 21.5 9.2 24 19 ...
##  $ Hg                       : num  NA 0 0 0 0 0 0.2 0.1 0.2 0.2 ...
##  $ Ni                       : num  NA 0.4 3.6 6.9 1.2 2 16.9 6.2 10.8 10.6 ...
##  $ Zn                       : num  NA 3.2 28.7 56.8 10.3 ...
##  $ X__2                     : chr  NA NA NA NA ...</code></pre>
<pre class="r"><code>head(datlocs)</code></pre>
<pre><code>##   FID StationID Bight Latitude Longitude
## 1   0      1001  1994 33.98533 -118.6077
## 2   1      1003  1994 33.98400 -118.5690
## 3   2      1005  1994 33.98250 -118.5373
## 4   3      1014  1994 33.97417 -118.5588
## 5   4      1019  1994 33.97067 -118.4800
## 6   5      1025  1994 33.96833 -118.4760</code></pre>
<pre class="r"><code>str(datlocs)</code></pre>
<pre><code>## &#39;data.frame&#39;:    1867 obs. of  5 variables:
##  $ FID      : int  0 1 2 3 4 5 6 7 8 9 ...
##  $ StationID: chr  &quot;1001&quot; &quot;1003&quot; &quot;1005&quot; &quot;1014&quot; ...
##  $ Bight    : int  1994 1994 1994 1994 1994 1994 1994 1994 1994 1994 ...
##  $ Latitude : num  34 34 34 34 34 ...
##  $ Longitude: num  -119 -119 -119 -119 -118 ...</code></pre>
</div>
<div id="data-wrangle" class="section level1">
<h1>Data wrangle</h1>
<p>Neither of our two datasets are in a format that allows us to easily evalute relationships among the variables. We’ll tackle the chemistry data first. We can’t work with the data in its current format because of some artificts left over when we imported the Excel spreadsheet. Here are a few of the issues we’ll have to handle:</p>
<ol style="list-style-type: decimal">
<li><p>Incorrect first row</p></li>
<li><p>Some columns we don’t care about</p></li>
<li><p>Some columns are character strings when they should be numeric</p></li>
<li><p>Some column names are inconvenient to work with, e.g., we don’t want to type out names with lots of mixed characters</p></li>
</ol>
<p>Here’s how we can address these issues step by step. First, remove the first row and overwrite the existing object:</p>
<pre class="r"><code>datchem &lt;- datchem[-1, ]</code></pre>
<p>Remove two columns we don’t need using the <code>select</code> function with the <code>-</code> sign. The amphipod survival column is redundant with <code>%Amph.</code> and <code>X__2</code> is a bunch of comments we don’t need.</p>
<pre class="r"><code>datchem &lt;- datchem %&gt;% 
  select(-`Amphipod survival (n =20)`, -`X__2`)</code></pre>
<p>An additional problem is that some columns were character strings but we know that every entry should be numeric. R will try to guess the types of values in a column when the data are imported. It will default to character data in ambiguous cases, i.e., a column contains a mix of numbers and letters. To fix this issue, we can use the <code>mutate_if</code> function that conditionally converts columns given some criteria. This is similar to the <code>mutate</code> function with an added twist by checking all columns at once.</p>
<pre class="r"><code>datchem &lt;- datchem %&gt;% 
  mutate_if(is.character, as.numeric)</code></pre>
<p>This appeared to work, but why did we get so many warning messages? This is R’s way of telling us that it tried and failed to convert something to a number. As a result, these entries were given an <code>NA</code> value. If you look at the original dataset, you’ll notice that some entries were given as <code>?</code>. These can’t be converted to numbers, so an <code>NA</code> value is fine in this case.</p>
<p>We’re almost done wrangling the chemistry dataset. Now we just need to rename some of the columns. Let’s rename anything that includes a “special character” or is otherwise inconvenient to work with.</p>
<pre class="r"><code>datchem &lt;- datchem %&gt;% 
  rename(
    station = `Station ID`, 
    depth = `Depth\r\n(m)`,
    amph_surv = X__1, 
    embr_surv = `%M.Emb.Surv.`
  ) </code></pre>
<p>Now we can start working with the location data, which will be much simpler to work with because it was already in a flat-file format. Our goal is to wrangle the data so that we can easily join it to the chemistry dataset. Our chemistry dataset is from Bight 2008 so we first want to filter the station location data for the same year.</p>
<pre class="r"><code>datlocs &lt;- datlocs %&gt;% 
  filter(Bight %in% 2008) </code></pre>
<p>Then we want to rename the StationID column to match that in our chemistry dataset. This will let us join the two datasets using a shared column name. The station column also has to be numeric to match the chemistry data.</p>
<pre class="r"><code>datlocs &lt;- datlocs %&gt;% 
  rename(station = StationID) %&gt;% 
  mutate(station = as.numeric(station))</code></pre>
<p>Finally, let’s remove the <code>FID</code> and <code>Bight</code> columns that we don’t need.</p>
<pre class="r"><code>datlocs &lt;- datlocs %&gt;% 
  select(-FID, -Bight)</code></pre>
<p>Here’s what our cleaned up chemistry and location datasets look like.</p>
<pre class="r"><code>head(datchem)</code></pre>
<pre><code>## # A tibble: 6 x 13
##   station depth amph_surv embr_surv    Al    As    Cr    Cu    Fe    Pb
##     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    6001   0.9        91        90  1040   1     1.4   0.5  1726   0.7
## 2    6004   0.8        92       100  6690   1.4   7.7   6    8100   4.1
## 3    6009   0.6        90         0 12700   3.1  13.3  13   13900  10  
## 4    6010   0.6        87        95  2615   0.7   2.6   1.9  3192   1.4
## 5    6012   0.8        95        95  4444   0.9   4.1   3.6  5248   2.5
## 6    6015   1.8        81        90 33130  10.6  47.3  60.1 37190  21.5
## # ... with 3 more variables: Hg &lt;dbl&gt;, Ni &lt;dbl&gt;, Zn &lt;dbl&gt;</code></pre>
<pre class="r"><code>head(datlocs)</code></pre>
<pre><code>##   station Latitude Longitude
## 1    6001 32.55658 -117.1281
## 2    6004 32.55737 -117.1224
## 3    6009 32.55920 -117.1160
## 4    6010 32.55935 -117.1112
## 5    6012 32.56244 -117.1084
## 6    6015 32.60756 -117.1224</code></pre>
<p>Now we can join the two to create a single dataset (see <a href="https://sccwrp.github.io/SCCWRP_R_training/Data_Wrangling_2.html#combining-data">here</a> for a refresher on joins). First let’s see if all the station IDs that are in our chemistry data are also in our location data.</p>
<pre class="r"><code>setdiff(datchem$station, datlocs$station)</code></pre>
<pre><code>## [1] 6093</code></pre>
<p>Okay, so there’s one station in our chemistry data that wasn’t in our location data. That’s okay and an acceptable loss. We’ll use the <code>inner_join()</code> function to combine the two datasets by the station id. This will drop all stations that aren’t shared between the two datasets.</p>
<pre class="r"><code>dat &lt;- inner_join(datlocs, datchem, by = &#39;station&#39;)</code></pre>
<p>We can verify that one station was lost by looking at the dimensions of the chemistry data compared to the joined data.</p>
<pre class="r"><code>dim(datchem)</code></pre>
<pre><code>## [1] 155  13</code></pre>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 154  15</code></pre>
<pre class="r"><code>head(dat)</code></pre>
<pre><code>##   station Latitude Longitude depth amph_surv embr_surv    Al   As   Cr
## 1    6001 32.55658 -117.1281   0.9        91        90  1040  1.0  1.4
## 2    6004 32.55737 -117.1224   0.8        92       100  6690  1.4  7.7
## 3    6009 32.55920 -117.1160   0.6        90         0 12700  3.1 13.3
## 4    6010 32.55935 -117.1112   0.6        87        95  2615  0.7  2.6
## 5    6012 32.56244 -117.1084   0.8        95        95  4444  0.9  4.1
## 6    6015 32.60756 -117.1224   1.8        81        90 33130 10.6 47.3
##     Cu    Fe   Pb  Hg   Ni    Zn
## 1  0.5  1726  0.7 0.0  0.4   3.2
## 2  6.0  8100  4.1 0.0  3.6  28.7
## 3 13.0 13900 10.0 0.0  6.9  56.8
## 4  1.9  3192  1.4 0.0  1.2  10.3
## 5  3.6  5248  2.5 0.0  2.0  17.4
## 6 60.1 37190 21.5 0.2 16.9 197.3</code></pre>
<p>The last and final step before we start addressing our research question is to identify and possibly remove outliers. There are quite a few definitions of what makes something an outlier. Generally speaking, these are values that are “far” from the central tendency of the rest of the data, where “far” could be defined many ways, e.g., 1.5 x the interquartile range, &gt; 95th percentile, etc. There’s no strict rule that applies to every dataset and the chosen definition depends on the needs of your analysis, and more importantly, what is considerable unacceptable in the eyes of you, the analyst.</p>
<p>For this analysis, we’re going to be looking at simple correlations among the variables. In this sense, any observations that can skew a perceived correlation could be considered an outlier and these would typically be values that are due to measurement error, human error, etc. A good first step would be to look at a pairs plot of the data. This is a matrix of all paired scatter plots for every variable in the dataset. We can use this to not only evalute relative associations but also find which pairs of values deviate wildly from the rest.</p>
<p>We’ll create a pairs plot by evaluating everything except the station column. We’ll set the argument <code>gap = 0</code> to minimize gaps between the plot panels to help us better see the plots. The argument <code>cex = 0.5</code> will reduce the point size to minimize clutter. Pro tip: you might get an error <span style="color:red">Error in plot.new() : figure margins too large</span>. This simply means that the figure margins in RStudio’s plot window (bottom right panel) are too small to plot the data. Use the <code>windows()</code> function from the command line to make a new graphics device that you can expand.</p>
<pre class="r"><code>pairs(dat[, -1], gap = 0, cex = 0.5)</code></pre>
<p><img src="R_luncheon_2_files/figure-html/unnamed-chunk-18-1.png" width="768" /></p>
<p>It looks like we have some problem values:</p>
<ul>
<li>amphipod survivability &lt; 40</li>
<li>chromium &gt; 100</li>
<li>mercury &gt; 3</li>
</ul>
<p>We’ll want to remove these by hand since these will likely cause problems, i.e., skewing correlation coefficients, linear models, etc. This is most easily done by selecting the variables from the dataset, subsetting by the offending values, and assigning an <code>NA</code> value. We can do this by indexing with base R or using dplyr syntax, your choice.</p>
<pre class="r"><code>dat$amph_surv[dat$amph_surv &lt; 40] &lt;- NA
dat$Cr[dat$Cr &gt; 100] &lt;- NA
dat$Hg[dat$Hg &gt; 3] &lt;- NA</code></pre>
<p>Using dplyr syntax, this can be accomplished with <code>ifelse</code> statements:</p>
<pre class="r"><code>dat &lt;- dat %&gt;% 
  mutate(
    amph_surv = ifelse(amph_surv &lt; 40, NA, amph_surv), 
    Cr = ifelse(Cr &gt; 100, NA, Cr), 
    Hg = ifelse(Hg &gt; 4, NA, Hg)
  )</code></pre>
<p>When this is done, we can verify that the offending values were removed by looking again at the pairs plot.</p>
<pre class="r"><code>pairs(dat[, -1], gap = 0, cex = 0.5)</code></pre>
<p><img src="R_luncheon_2_files/figure-html/unnamed-chunk-21-1.png" width="768" /></p>
<p>This is a relatively subjective approach to removing outliers. At the end of the day, the true test is whether including or removing outliers changes the conclusions of the analysis results. If the results don’t change, than don’t remove the values. If they do change, consider what may have caused the erroneous values. Some values may be obviously wrong (e.g., outside of the possible range of expected values) or others may require consulting the original data. You can try the below analysis by retaining the outliers to see if the conclusions change but for now we’ll proceed with them removed.</p>
</div>
<div id="data-analysis" class="section level1">
<h1>Data analysis</h1>
<p>Now we can start addressing our research questions. Our first question is whether or not any of thes variables following some kind of spatial pattern. This would suggest something about location is affecting sediment toxicity, such as different origins or different management actions that influence source/sink dynamics. We can get a visual representation of these patterns by looking at how they vary by latitude and longitude.</p>
<p>We can use ggplot for a quick assessment.</p>
<pre class="r"><code>ggplot(dat, aes(x = Longitude, y = Latitude)) +
  geom_point() + 
  coord_cartesian()</code></pre>
<p><img src="R_luncheon_2_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Now let’s overlay some of the survivability estimates on the points (you can swap out any of the other toxicity measures using the <code>colour</code> aesthetic).</p>
<pre class="r"><code>ggplot(dat, aes(x = Longitude, y = Latitude, colour = amph_surv)) +
  geom_point() + 
  coord_cartesian()</code></pre>
<p><img src="R_luncheon_2_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>It looks like there are some patterns within bays but definitely nothing consistent across latitude or longitude. In fact, you can verify the lack of association by looking at the pairs plot above.</p>
<p>There may be specific contaminants that vary spatially within each bay that are driving the changes. To get a handle on which contaminants may be driving the exposure results, we can use a more quantitative plot to link the variables. The GGally package is of great help here.</p>
<pre class="r"><code>install.package(&#39;GGally&#39;)
library(GGally)</code></pre>
<p>We can use the <code>ggpairs</code> function to make a beefed up version of the pairs plot. In addition to paired scatterplots, you can get a better idea of the distribution of each variable and actual estimates of correlations between pairs of variables. We’ll not look at the station, latitude, or longitude columns for this example.</p>
<pre class="r"><code>ggpairs(dat[, -c(1:3)])</code></pre>
<p><img src="R_luncheon_2_files/figure-html/unnamed-chunk-26-1.png" width="768" /></p>
<p>Great, now we’ve got some numbers. Some of the chemical variables are clearly correlated with each other, whereas the degree of association with survivability varies. Some of these associations may not even be linear and there may be other variables that are not captured in this dataset that describe the trends.</p>
<p>If we want to dig further, we can look at any of the individual pairs for more detailed analysis. This example shows a simple correlation test and a linear model to evaluate additive effects.</p>
<pre class="r"><code>cor.test(dat$amph_surv, dat$Hg)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  dat$amph_surv and dat$Hg
## t = 1.7418, df = 149, p-value = 0.0836
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.01888841  0.29435289
## sample estimates:
##       cor 
## 0.1412663</code></pre>
<pre class="r"><code>mod &lt;- lm(embr_surv ~ Pb + Fe, dat)
summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = embr_surv ~ Pb + Fe, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -87.426  -3.556   5.530  12.152  35.218 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 84.3694495  4.9203106  17.147   &lt;2e-16 ***
## Pb          -0.0112606  0.0944513  -0.119    0.905    
## Fe           0.0002280  0.0002217   1.029    0.305    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 23.42 on 139 degrees of freedom
##   (12 observations deleted due to missingness)
## Multiple R-squared:  0.009977,   Adjusted R-squared:  -0.004268 
## F-statistic: 0.7004 on 2 and 139 DF,  p-value: 0.4981</code></pre>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Clearly this simple analysis is not doing this dataset justice, but we’ve identified an analysis workflow that identifies significant associations for follow-up analysis. A good starting place would be to look at individual bays to minimize variation between locations. Alternatively, a formal multivariate analysis that simultaneously compares all the data could be insightful (for example, <a href="https://fawda123.github.io/sed_chem_tox/sed_chem_tox.html">here</a>). Either way, we’ve covered some of the basics for good data stewardship defined within the constraints of our question. These methods have value for any data analysis workflow.</p>
<div class="figure">
<img src="figure/luncheon2workflow.png" />

</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
